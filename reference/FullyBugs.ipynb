{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e2a0fdd3b3f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprogress_bar_downloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Hosting files on my dropbox since downloading from google code is painful\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Original project hosting is here: https://code.google.com/p/hmm-speech-recognition/downloads/list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from utils import progress_bar_downloader\n",
    "import os\n",
    "\n",
    "#Hosting files on my dropbox since downloading from google code is painful\n",
    "#Original project hosting is here: https://code.google.com/p/hmm-speech-recognition/downloads/list\n",
    "#Audio is included in the zip file\n",
    "#link = 'https://dl.dropboxusercontent.com/u/15378192/audio.tar.gz'\n",
    "dlname = 'audio.zip'\n",
    "\n",
    "if not os.path.exists('./%s' % dlname):\n",
    "    progress_bar_downloader(link, dlname)\n",
    "    os.system('tar xzf %s' % dlname)\n",
    "else:\n",
    "    print('%s already downloaded!' % dlname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fpaths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f89563c032bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fpaths' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#Files can be heard in Linux using the following commands from the command line\n",
    "#cat kiwi07.wav | aplay -f S16_LE -t wav -r 8000\n",
    "#Files are signed 16 bit raw, sample rate 8000\n",
    "from scipy.io import wavfile\n",
    "\n",
    "data = np.zeros((len(fpaths), 32000))\n",
    "maxsize = -1\n",
    "for n,file in enumerate(fpaths):\n",
    "    _, d = wavfile.read(file)\n",
    "    data[n, :d.shape[0]] = d\n",
    "    if d.shape[0] > maxsize:\n",
    "        maxsize = d.shape[0]\n",
    "data = data[:, :maxsize]\n",
    "\n",
    "#Each sample file is one row in data, and has one entry in labels\n",
    "print('Number of files total:', data.shape[0])\n",
    "all_labels = np.zeros(data.shape[0])\n",
    "for n, l in enumerate(set(labels)):\n",
    "    all_labels[np.array([i for i, _ in enumerate(labels) if _ == l])] = n\n",
    "    \n",
    "print('Labels and label indices', all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def stft(x, fftsize=64, overlap_pct=.5):   \n",
    "    #Modified from http://stackoverflow.com/questions/2459295/stft-and-istft-in-python\n",
    "    hop = int(fftsize * (1 - overlap_pct))\n",
    "    w = scipy.hanning(fftsize + 1)[:-1]    \n",
    "    raw = np.array([np.fft.rfft(w * x[i:i + fftsize]) for i in range(0, len(x) - fftsize, hop)])\n",
    "    return raw[:, :(fftsize // 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4a83c4951db6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steelblue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Timeseries example for %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data[0, :], color='steelblue')\n",
    "plt.title('Timeseries example for %s'%labels[0])\n",
    "plt.xlim(0, 3500)\n",
    "plt.xlabel('Time (samples)')\n",
    "plt.ylabel('Amplitude (signed 16 bit)')\n",
    "plt.figure()\n",
    "\n",
    "# + 1 to avoid log of 0\n",
    "log_freq = 20 * np.log(np.abs(stft(data[0, :])) + 1)\n",
    "print(log_freq.shape)\n",
    "plt.imshow(log_freq, cmap='gray', interpolation=None)\n",
    "plt.xlabel('Freq (bin)')\n",
    "plt.ylabel('Time (overlapped frames)')\n",
    "plt.ylim(log_freq.shape[1])\n",
    "plt.title('PSD of %s example'%labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "#Peak detection using the technique described here: http://kkjkok.blogspot.com/2013/12/dsp-snippets_9.html \n",
    "def peakfind(x, n_peaks, l_size=3, r_size=3, c_size=3, f=np.mean):\n",
    "    win_size = l_size + r_size + c_size\n",
    "    shape = x.shape[:-1] + (x.shape[-1] - win_size + 1, win_size)\n",
    "    strides = x.strides + (x.strides[-1],)\n",
    "    xs = as_strided(x, shape=shape, strides=strides)\n",
    "    def is_peak(x):\n",
    "        centered = (np.argmax(x) == l_size + int(c_size/2))\n",
    "        l = x[:l_size]\n",
    "        c = x[l_size:l_size + c_size]\n",
    "        r = x[-r_size:]\n",
    "        passes = np.max(c) > np.max([f(l), f(r)])\n",
    "        if centered and passes:\n",
    "            return np.max(c)\n",
    "        else:\n",
    "            return -1\n",
    "    r = np.apply_along_axis(is_peak, 1, xs)\n",
    "    top = np.argsort(r, None)[::-1]\n",
    "    heights = r[top[:n_peaks]]\n",
    "    #Add l_size and half - 1 of center size to get to actual peak location\n",
    "    top[top > -1] = top[top > -1] + l_size + int(c_size / 2.)\n",
    "    return heights, top[:n_peaks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e628b40fdc36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeakfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_peaks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steelblue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stft' is not defined"
     ]
    }
   ],
   "source": [
    "plot_data = np.abs(stft(data[20, :]))[15, :]\n",
    "values, locs = peakfind(plot_data, n_peaks=6)\n",
    "fp = locs[values > -1]\n",
    "fv = values[values > -1]\n",
    "plt.plot(plot_data, color='steelblue')\n",
    "plt.plot(fp, fv, 'x', color='darkred')\n",
    "plt.title('Peak location example')\n",
    "plt.xlabel('Frequency (bins)')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-74c72a889c0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#MFCC (or deep NN/automatic feature extraction) could be interesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mall_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mn_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#This processing (top freq peaks) only works for single speaker case... need better features for multispeaker!\n",
    "#MFCC (or deep NN/automatic feature extraction) could be interesting\n",
    "all_obs = []\n",
    "for i in range(data.shape[0]):\n",
    "    d = np.abs(stft(data[i, :]))\n",
    "    n_dim = 6\n",
    "    obs = np.zeros((n_dim, d.shape[0]))\n",
    "    for r in range(d.shape[0]):\n",
    "        _, t = peakfind(d[r, :], n_peaks=n_dim)\n",
    "        obs[:, r] = t.copy()\n",
    "    if i % 10 == 0:\n",
    "        print(\"Processed obs %s\" % i)\n",
    "    all_obs.append(obs)\n",
    "    \n",
    "all_obs = np.atleast_3d(all_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihoods for test set 1\n",
      "M1: 221.38828575112734\n",
      "M2: 165.27280230776492\n",
      "Prediction for test set 1\n",
      "Model 1\n",
      "\n",
      "Likelihoods for test set 2\n",
      "M1: 33.19459421485196\n",
      "M2: 59.15274753052999\n",
      "Prediction for test set 2\n",
      "Model 2\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "\n",
    "class gmmhmm:\n",
    "    #This class converted with modifications from https://code.google.com/p/hmm-speech-recognition/source/browse/Word.m\n",
    "    def __init__(self, n_states):\n",
    "        self.n_states = n_states\n",
    "        self.random_state = np.random.RandomState(0)\n",
    "        \n",
    "        #Normalize random initial state\n",
    "        self.prior = self._normalize(self.random_state.rand(self.n_states, 1))\n",
    "        self.A = self._stochasticize(self.random_state.rand(self.n_states, self.n_states))\n",
    "        \n",
    "        self.mu = None\n",
    "        self.covs = None\n",
    "        self.n_dims = None\n",
    "           \n",
    "    def _forward(self, B):\n",
    "        log_likelihood = 0.\n",
    "        T = B.shape[1]\n",
    "        alpha = np.zeros(B.shape)\n",
    "        for t in range(T):\n",
    "            if t == 0:\n",
    "                alpha[:, t] = B[:, t] * self.prior.ravel()\n",
    "            else:\n",
    "                alpha[:, t] = B[:, t] * np.dot(self.A.T, alpha[:, t - 1])\n",
    "         \n",
    "            alpha_sum = np.sum(alpha[:, t])\n",
    "            alpha[:, t] /= alpha_sum\n",
    "            log_likelihood = log_likelihood + np.log(alpha_sum)\n",
    "        return log_likelihood, alpha\n",
    "    \n",
    "    def _backward(self, B):\n",
    "        T = B.shape[1]\n",
    "        beta = np.zeros(B.shape);\n",
    "           \n",
    "        beta[:, -1] = np.ones(B.shape[0])\n",
    "            \n",
    "        for t in range(T - 1)[::-1]:\n",
    "            beta[:, t] = np.dot(self.A, (B[:, t + 1] * beta[:, t + 1]))\n",
    "            beta[:, t] /= np.sum(beta[:, t])\n",
    "        return beta\n",
    "    \n",
    "    def _state_likelihood(self, obs):\n",
    "        obs = np.atleast_2d(obs)\n",
    "        B = np.zeros((self.n_states, obs.shape[1]))\n",
    "        for s in range(self.n_states):\n",
    "            #Needs scipy 0.14\n",
    "            np.random.seed(self.random_state.randint(1))\n",
    "            B[s, :] = st.multivariate_normal.pdf(\n",
    "                obs.T, mean=self.mu[:, s].T, cov=self.covs[:, :, s].T)\n",
    "            #This function can (and will!) return values >> 1\n",
    "            #See the discussion here for the equivalent matlab function\n",
    "            #https://groups.google.com/forum/#!topic/comp.soft-sys.matlab/YksWK0T74Ak\n",
    "            #Key line: \"Probabilities have to be less than 1,\n",
    "            #Densities can be anything, even infinite (at individual points).\"\n",
    "            #This is evaluating the density at individual points...\n",
    "        return B\n",
    "    \n",
    "    def _normalize(self, x):\n",
    "        return (x + (x == 0)) / np.sum(x)\n",
    "    \n",
    "    def _stochasticize(self, x):\n",
    "        return (x + (x == 0)) / np.sum(x, axis=1)\n",
    "    \n",
    "    def _em_init(self, obs):\n",
    "        #Using this _em_init function allows for less required constructor args\n",
    "        if self.n_dims is None:\n",
    "            self.n_dims = obs.shape[0]\n",
    "        if self.mu is None:\n",
    "            subset = self.random_state.choice(np.arange(self.n_dims), size=self.n_states, replace=False)\n",
    "            self.mu = obs[:, subset]\n",
    "        if self.covs is None:\n",
    "            self.covs = np.zeros((self.n_dims, self.n_dims, self.n_states))\n",
    "            self.covs += np.diag(np.diag(np.cov(obs)))[:, :, None]\n",
    "        return self\n",
    "    \n",
    "    def _em_step(self, obs): \n",
    "        obs = np.atleast_2d(obs)\n",
    "        B = self._state_likelihood(obs)\n",
    "        T = obs.shape[1]\n",
    "        \n",
    "        log_likelihood, alpha = self._forward(B)\n",
    "        beta = self._backward(B)\n",
    "        \n",
    "        xi_sum = np.zeros((self.n_states, self.n_states))\n",
    "        gamma = np.zeros((self.n_states, T))\n",
    "        \n",
    "        for t in range(T - 1):\n",
    "            partial_sum = self.A * np.dot(alpha[:, t], (beta[:, t] * B[:, t + 1]).T)\n",
    "            xi_sum += self._normalize(partial_sum)\n",
    "            partial_g = alpha[:, t] * beta[:, t]\n",
    "            gamma[:, t] = self._normalize(partial_g)\n",
    "              \n",
    "        partial_g = alpha[:, -1] * beta[:, -1]\n",
    "        gamma[:, -1] = self._normalize(partial_g)\n",
    "        \n",
    "        expected_prior = gamma[:, 0]\n",
    "        expected_A = self._stochasticize(xi_sum)\n",
    "        \n",
    "        expected_mu = np.zeros((self.n_dims, self.n_states))\n",
    "        expected_covs = np.zeros((self.n_dims, self.n_dims, self.n_states))\n",
    "        \n",
    "        gamma_state_sum = np.sum(gamma, axis=1)\n",
    "        #Set zeros to 1 before dividing\n",
    "        gamma_state_sum = gamma_state_sum + (gamma_state_sum == 0)\n",
    "        \n",
    "        for s in range(self.n_states):\n",
    "            gamma_obs = obs * gamma[s, :]\n",
    "            expected_mu[:, s] = np.sum(gamma_obs, axis=1) / gamma_state_sum[s]\n",
    "            partial_covs = np.dot(gamma_obs, obs.T) / gamma_state_sum[s] - np.dot(expected_mu[:, s], expected_mu[:, s].T)\n",
    "            #Symmetrize\n",
    "            partial_covs = np.triu(partial_covs) + np.triu(partial_covs).T - np.diag(partial_covs)\n",
    "        \n",
    "        #Ensure positive semidefinite by adding diagonal loading\n",
    "        expected_covs += .01 * np.eye(self.n_dims)[:, :, None]\n",
    "        \n",
    "        self.prior = expected_prior\n",
    "        self.mu = expected_mu\n",
    "        self.covs = expected_covs\n",
    "        self.A = expected_A\n",
    "        return log_likelihood\n",
    "    \n",
    "    def fit(self, obs, n_iter=15):\n",
    "        #Support for 2D and 3D arrays\n",
    "        #2D should be n_features, n_dims\n",
    "        #3D should be n_examples, n_features, n_dims\n",
    "        #For example, with 6 features per speech segment, 105 different words\n",
    "        #this array should be size\n",
    "        #(105, 6, X) where X is the number of frames with features extracted\n",
    "        #For a single example file, the array should be size (6, X)\n",
    "        if len(obs.shape) == 2:\n",
    "            for i in range(n_iter):\n",
    "                self._em_init(obs)\n",
    "                log_likelihood = self._em_step(obs)\n",
    "        elif len(obs.shape) == 3:\n",
    "            count = obs.shape[0]\n",
    "            for n in range(count):\n",
    "                for i in range(n_iter):\n",
    "                    self._em_init(obs[n, :, :])\n",
    "                    log_likelihood = self._em_step(obs[n, :, :])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, obs):\n",
    "        #Support for 2D and 3D arrays\n",
    "        #2D should be n_features, n_dims\n",
    "        #3D should be n_examples, n_features, n_dims\n",
    "        #For example, with 6 features per speech segment, 105 different words\n",
    "        #this array should be size\n",
    "        #(105, 6, X) where X is the number of frames with features extracted\n",
    "        #For a single example file, the array should be size (6, X)\n",
    "        if len(obs.shape) == 2:\n",
    "            B = self._state_likelihood(obs)\n",
    "            log_likelihood, _ = self._forward(B)\n",
    "            return log_likelihood\n",
    "        elif len(obs.shape) == 3:\n",
    "            count = obs.shape[0]\n",
    "            out = np.zeros((count,))\n",
    "            for n in range(count):\n",
    "                B = self._state_likelihood(obs[n, :, :])\n",
    "                log_likelihood, _ = self._forward(B)\n",
    "                out[n] = log_likelihood\n",
    "            return out\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rstate = np.random.RandomState(0)\n",
    "    t1 = np.ones((4, 40)) + .001 * rstate.rand(4, 40)\n",
    "    t1 /= t1.sum(axis=0)\n",
    "    t2 = rstate.rand(*t1.shape)\n",
    "    t2 /= t2.sum(axis=0)\n",
    "    \n",
    "    m1 = gmmhmm(2)\n",
    "    m1.fit(t1)\n",
    "    m2 = gmmhmm(2)\n",
    "    m2.fit(t2)\n",
    "    \n",
    "    m1t1 = m1.transform(t1)\n",
    "    m2t1 = m2.transform(t1)\n",
    "    print(\"Likelihoods for test set 1\")\n",
    "    print(\"M1:\", m1t1)\n",
    "    print(\"M2:\", m2t1)\n",
    "    print(\"Prediction for test set 1\")\n",
    "    print(\"Model\", np.argmax([m1t1, m2t1]) + 1)\n",
    "    print()\n",
    "    \n",
    "    m1t2 = m1.transform(t2)\n",
    "    m2t2 = m2.transform(t2)\n",
    "    print(\"Likelihoods for test set 2\")\n",
    "    print(\"M1:\", m1t2)\n",
    "    print(\"M2:\", m2t2)\n",
    "    print(\"Prediction for test set 2\")\n",
    "    print(\"Model\", np.argmax([m1t2, m2t2]) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiayuewang/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8392f4e5037a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_obs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mall_obs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_labels' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(all_labels, test_size=0.1, random_state=0)\n",
    "\n",
    "for n,i in enumerate(all_obs):\n",
    "    all_obs[n] /= all_obs[n].sum(axis=0)\n",
    "\n",
    "for train_index, test_index in sss:\n",
    "    X_train, X_test = all_obs[train_index, ...], all_obs[test_index, ...]\n",
    "    y_train, y_test = all_labels[train_index], all_labels[test_index]\n",
    "print('Size of training matrix:', X_train.shape)\n",
    "print('Size of testing matrix:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = set(all_labels)\n",
    "ms = [gmmhmm(6) for y in ys]\n",
    "_ = [m.fit(X_train[y_train == y, :, :]) for m, y in zip(ms, ys)]\n",
    "ps = [m.transform(X_test) for m in ms]\n",
    "res = np.vstack(ps)\n",
    "predicted_labels = np.argmax(res, axis=0)\n",
    "missed = (predicted_labels != y_test)\n",
    "print('Test accuracy: %.2f percent' % (100 * (1 - np.mean(missed))))\n",
    "Test accuracy: 71.43 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, predicted_labels)\n",
    "plt.matshow(cm, cmap='gray')\n",
    "ax = plt.gca()\n",
    "_ = ax.set_xticklabels([\" \"] + [l[:2] for l in spoken])\n",
    "_ = ax.set_yticklabels([\" \"] + spoken)\n",
    "plt.title('Confusion matrix, single speaker')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
